{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fea1572a",
   "metadata": {},
   "source": [
    "The exchange I'm implementing is Australian Tax Office's mobile phone support.\n",
    "\n",
    "Intents to handle:\n",
    "\n",
    "- Check the progress of your tax return\n",
    "- Request your existing tax file number\n",
    "- Tax return preparation\n",
    "- Linking myGov to myTax\n",
    "\n",
    "Phrases to try:\n",
    "\n",
    "- When do I get my tax return? Tax return progress?\n",
    "- What is my tax file number? What is my TFN?\n",
    "- I need help preparing my tax return. How I can do my tax return?\n",
    "- I need to link myGov to myTax. How can I link myGov account to myTax?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ca5f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import time\n",
    "import numpy as np\n",
    "import whisper\n",
    "import ollama\n",
    "import json\n",
    "import logging\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4e59043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00039673, 0.00039673],\n",
       "       [0.00033569, 0.00033569],\n",
       "       [0.00027466, 0.00027466],\n",
       "       ...,\n",
       "       [0.00021362, 0.00018311],\n",
       "       [0.00021362, 0.00021362],\n",
       "       [0.00021362, 0.00021362]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is function to play audio\n",
    "\n",
    "def playaudio(file):\n",
    "    \n",
    "    # Read the audio file as a NumPy array\n",
    "    data, fs = sf.read(file, dtype='float32')\n",
    "\n",
    "    # Play the audio file using sounddevice\n",
    "    sd.play(data, fs)\n",
    "\n",
    "    # Wait until the file is done playing\n",
    "    status = sd.wait()\n",
    "    \n",
    "    return data\n",
    "    \n",
    "#This is to play the greetings\n",
    "playaudio('audio/greetings.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebf9fee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is function to record audio\n",
    "\n",
    "def record_audio(file, duration):\n",
    "    # Set the sampling frequency\n",
    "    fs = 44100\n",
    "    # Record audio using sounddevice\n",
    "    data = sd.rec(int(duration * fs), samplerate=fs, channels=2)\n",
    "    print(\"Recording started...\")\n",
    "    # Wait until the recording is done\n",
    "    status = sd.wait()\n",
    "    print(\"Recording stopped.\")\n",
    "    # Save the recorded audio to a file using soundfile\n",
    "    sf.write(file, data, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cabe5aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording started...\n",
      "Recording stopped.\n"
     ]
    }
   ],
   "source": [
    "#This is to record the customer's intent\n",
    "\n",
    "record_audio('audio/intent.wav', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9006da77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What is my text file number?\n"
     ]
    }
   ],
   "source": [
    "#This is to transcribe the customer's intent.\n",
    "\n",
    "model = whisper.load_model(\"base\").to('cpu')\n",
    "\n",
    "intent = model.transcribe('audio/intent.wav')\n",
    "print(intent['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69f6660e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I need help preparing my tax return.\n",
      " What is my tax file number?\n",
      " When do I get my tax return?\n",
      " I need to link my gov to my tax.\n"
     ]
    }
   ],
   "source": [
    "#These are all the 4 intents I pre-recorded, which can help if you want to test different intents\n",
    "\n",
    "intent_check = model.transcribe(\"audio/check_question.wav\")\n",
    "intent_prepare = model.transcribe(\"audio/prepare_question.wav\")\n",
    "intent_request = model.transcribe(\"audio/request_question.wav\")\n",
    "intent_link = model.transcribe(\"audio/link_question.wav\")\n",
    "\n",
    "print(intent_prepare['text'])\n",
    "print(intent_request['text'])\n",
    "print(intent_check['text'])\n",
    "print(intent_link['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd517b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is for logging the transcription\n",
    "\n",
    "transcription_intent = intent['text']\n",
    "\n",
    "# Set the file name and format of the log file\n",
    "log_file = \"transcript.log\"\n",
    "log_format = \"%(asctime)s %(message)s\"\n",
    "\n",
    "# Configure the logging settings\n",
    "logging.basicConfig(filename=log_file, format=log_format, level=logging.INFO)\n",
    "\n",
    "# Write a message to the log file\n",
    "logging.info(transcription_intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe86a755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9984287619590759}]\n",
      "operator\n"
     ]
    }
   ],
   "source": [
    "#This is to identify the sentiment of the customer's intent\n",
    "\n",
    "classifier = pipeline(task=\"sentiment-analysis\", model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "sentiment = classifier(transcription_intent)\n",
    "print(sentiment)\n",
    "\n",
    "#This is to print the word operator, if the intent is negative enough\n",
    "if sentiment[0]['label'] == 'NEGATIVE' and sentiment[0]['score'] > 0.99:\n",
    "    print(\"operator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2064a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'Tax return preparation'}\n"
     ]
    }
   ],
   "source": [
    "#This is to use few-shot learning to classify the intent of the customer into 1 of 4 pre-designed intents\n",
    "\n",
    "intent_prompt = 'There are 5 types of intents: Check the progress of your tax return, Request your existing tax file number, Tax return preparation, Linking myGov to myTax, and Irrelevant. If the text is like \"When do I get my tax return?\" or \"Tax return progress\", the intent is \"Check the progress of your tax return\". If the text is like \"What is my tax file number?\" or \"What is my TFN?\", the intent is \"Request your existing tax file number\". If the text is like \"I need help preparing my tax return\" or \"How I can do my tax return?\", the intent is \"Tax return preparation\". If the text is like \"I need to link my myGov to myTax\" or \"How can I link myGov to myTax\", the intent is \"Linking myGov to myTax\". Otherwise, the text is \"Irrrelevant\". Tag the following text with one of the intents: How can I do my tax return'\n",
    "\n",
    "r = ollama.generate(\n",
    "    model='gemma:2b', \n",
    "    prompt=intent_prompt,\n",
    "    format='json')\n",
    "\n",
    "answers = json.loads(r['response'])\n",
    "\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e28b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to play a confirmation question audio following the classification of customer's intent\n",
    "\n",
    "if answers['intent'] == 'Check the progress of your tax return':\n",
    "    playaudio('audio/check.wav')\n",
    "elif answers['intent'] == 'Request your existing tax file number':\n",
    "    playaudio('audio/request.wav')\n",
    "elif answers['intent'] == 'Tax return preparation':\n",
    "    playaudio('audio/prepare.wav')\n",
    "elif answers['intent'] == 'Linking myGov to myTax':\n",
    "    playaudio('audio/link.wav')\n",
    "else:\n",
    "    print('confused')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d61d215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording started...\n",
      "Recording stopped.\n"
     ]
    }
   ],
   "source": [
    "#This is to record the customer's response to the confirmation question\n",
    "\n",
    "record_audio('audio/response.wav', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8667263b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Yes, it is.\n"
     ]
    }
   ],
   "source": [
    "#This is to transcribe the response\n",
    "\n",
    "model = whisper.load_model(\"base\").to('cpu')\n",
    "\n",
    "response = model.transcribe('audio/response.wav')\n",
    "transcription_response = response['text']\n",
    "print(transcription_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "510ba7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gemma:2b', 'created_at': '2024-03-10T11:54:16.7771726Z', 'response': 'The statement \"Yes, it is\" is a yes. It is a statement that is true and indicates the present truth.', 'done': True, 'context': [106, 1645, 108, 212107, 573, 2412, 685, 6508, 7778, 689, 793, 235292, 139, 3553, 235269, 665, 603, 235265, 107, 108, 106, 2516, 108, 651, 6218, 664, 3553, 235269, 665, 603, 235281, 603, 476, 7778, 235265, 1165, 603, 476, 6218, 674, 603, 1382, 578, 14939, 573, 2835, 7873, 235265, 107, 108], 'total_duration': 4609359400, 'load_duration': 7641200, 'prompt_eval_duration': 211771000, 'eval_count': 26, 'eval_duration': 4376480000}\n"
     ]
    }
   ],
   "source": [
    "response = ollama.generate(model='gemma:2b', prompt='Classify the following as saying yes or no: '+transcription_response)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "020ea1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tax return preparation\n"
     ]
    }
   ],
   "source": [
    "#This is to play the final thanking audio, and print out the intent that was identified.\n",
    "\n",
    "for word in ['yes', 'yep', 'yeah', 'true', 'yea']:\n",
    "    if word in response['response'].lower():\n",
    "        playaudio('audio/thanks.wav')\n",
    "        print(answers['intent'])\n",
    "        break\n",
    "else:\n",
    "    print('confused')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
