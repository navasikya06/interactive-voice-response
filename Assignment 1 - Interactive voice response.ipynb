{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fea1572a",
   "metadata": {},
   "source": [
    "The exchange I'm implementing is Australian Tax Office's mobile phone support.\n",
    "\n",
    "Intents to handle:\n",
    "\n",
    "- Check the progress of your tax return\n",
    "- Request your existing tax file number\n",
    "- Tax return preparation\n",
    "- Linking myGov to myTax\n",
    "\n",
    "Phrases to try:\n",
    "\n",
    "- When do I get my tax return? Tax return progress?\n",
    "- What is my tax file number? What is my TFN?\n",
    "- I need help preparing my tax return. How I can do my tax return?\n",
    "- I need to link myGov to myTax. How can I link myGov account to myTax?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ca5f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import time\n",
    "import numpy as np\n",
    "import whisper\n",
    "import ollama\n",
    "import json\n",
    "import logging\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4e59043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00039673, 0.00039673],\n",
       "       [0.00033569, 0.00033569],\n",
       "       [0.00027466, 0.00027466],\n",
       "       ...,\n",
       "       [0.00021362, 0.00018311],\n",
       "       [0.00021362, 0.00021362],\n",
       "       [0.00021362, 0.00021362]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is function to play audio\n",
    "\n",
    "def playaudio(file):\n",
    "    \n",
    "    # Read the audio file as a NumPy array\n",
    "    data, fs = sf.read(file, dtype='float32')\n",
    "\n",
    "    # Play the audio file using sounddevice\n",
    "    sd.play(data, fs)\n",
    "\n",
    "    # Wait until the file is done playing\n",
    "    status = sd.wait()\n",
    "    \n",
    "    return data\n",
    "    \n",
    "#This is to play the greetings\n",
    "playaudio('audio/greetings.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ebf9fee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is function to record audio\n",
    "\n",
    "def record_audio(file, duration):\n",
    "    # Set the sampling frequency\n",
    "    fs = 44100\n",
    "    # Record audio using sounddevice\n",
    "    data = sd.rec(int(duration * fs), samplerate=fs, channels=2)\n",
    "    print(\"Recording started...\")\n",
    "    # Wait until the recording is done\n",
    "    status = sd.wait()\n",
    "    print(\"Recording stopped.\")\n",
    "    # Save the recorded audio to a file using soundfile\n",
    "    sf.write(file, data, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cabe5aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording started...\n",
      "Recording stopped.\n"
     ]
    }
   ],
   "source": [
    "#This is to record the customer's intent\n",
    "\n",
    "record_audio('audio/intent.wav', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9006da77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TChu0702\\lib\\site-packages\\whisper\\transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Link my gov to my tax.\n"
     ]
    }
   ],
   "source": [
    "#This is to transcribe the customer's intent.\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "intent = model.transcribe('audio/intent.wav')\n",
    "print(intent['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f6660e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TChu0702\\lib\\site-packages\\whisper\\transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I need help preparing my tax return.\n",
      " What is my tax file number?\n",
      " When do I get my tax return?\n",
      " I need to link my gov to my tax.\n"
     ]
    }
   ],
   "source": [
    "#These are all the 4 intents I pre-recorded, which can help if you want to test different intents\n",
    "\n",
    "intent_check = model.transcribe(\"audio/check_question.wav\")\n",
    "intent_prepare = model.transcribe(\"audio/prepare_question.wav\")\n",
    "intent_request = model.transcribe(\"audio/request_question.wav\")\n",
    "intent_link = model.transcribe(\"audio/link_question.wav\")\n",
    "\n",
    "print(intent_prepare['text'])\n",
    "print(intent_request['text'])\n",
    "print(intent_check['text'])\n",
    "print(intent_link['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd517b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is for logging the transcription\n",
    "\n",
    "transcription_intent = intent['text']\n",
    "\n",
    "# Set the file name and format of the log file\n",
    "log_file = \"transcript.log\"\n",
    "log_format = \"%(asctime)s %(message)s\"\n",
    "\n",
    "# Configure the logging settings\n",
    "logging.basicConfig(filename=log_file, format=log_format, level=logging.INFO)\n",
    "\n",
    "# Write a message to the log file\n",
    "logging.info(transcription_intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe86a755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9828671813011169}]\n"
     ]
    }
   ],
   "source": [
    "#This is to identify the sentiment of the customer's intent\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "sentiment = classifier(transcription_intent)\n",
    "print(sentiment)\n",
    "\n",
    "#This is to print operator, if the intent is negative enough\n",
    "if sentiment[0]['label'] == 'NEGATIVE' and sentiment[0]['score'] > 0.99:\n",
    "    print(\"operator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2064a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to use few-shot learning to classify the intent of the customer into 1 of 4 pre-designed intents\n",
    "\n",
    "r = ollama.generate(\n",
    "    model='gemma:2b', \n",
    "    prompt='For questions like \"When do I get my tax return?\" or \"Tax return progress\", the intent is \"Check the progress of your tax return\". For questions like \"What is my tax file number?\" or \"What is my TFN?\", the intent is \"Request your existing tax file number\". For questions like, the intent is. For questions like \"I need help preparing my tax return\" or \"How I can do my tax return?\", the intent is \"Tax return preparation\". For questions like \"I need to link my myGov to myTax\" or \"How can I link myGov to myTax\", the intent is \"Linking myGov to myTax\". Otherwise, the question is irrelevant. Tag the following transcription with one of the following intent: Check the progress of your tax return, Request your existing tax file number, Tax return preparation, Linking myGov to myTax, or Irrelevant: '+transcription_intent,\n",
    "    format='json')\n",
    "\n",
    "answers = json.loads(r['response'])\n",
    "\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0e28b6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confused\n"
     ]
    }
   ],
   "source": [
    "#This is to play a confirmation question audio following the classification of customer's intent\n",
    "\n",
    "if answers['intent'] == 'Check the progress of your tax return':\n",
    "    playaudio('audio/check.wav')\n",
    "elif answers['intent'] == 'Request your existing tax file number':\n",
    "    playaudio('audio/request.wav')\n",
    "elif answers['intent'] == 'Tax return preparation':\n",
    "    playaudio('audio/prepare.wav')\n",
    "elif answers['intent'] == 'Linking myGov to myTax':\n",
    "    playaudio('audio/link.wav')\n",
    "else:\n",
    "    print('confused')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0d61d215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording started...\n",
      "Recording stopped.\n"
     ]
    }
   ],
   "source": [
    "#This is to record the customer's response to the confirmation question\n",
    "\n",
    "record_audio('audio/response.wav', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8667263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to transcribe the response\n",
    "response = model.transcribe('audio/response.wav')\n",
    "transcription_response = response['text']\n",
    "print(transcription_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4798c435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to classify the response as affirmative or negative\n",
    "rr = ollama.generate(\n",
    "    model='gemma:2b', \n",
    "    prompt='Tag the following transcription with affirmative or negative '+transcription_response,\n",
    "    format='json')\n",
    "\n",
    "answerss = json.loads(rr['response'])\n",
    "\n",
    "print(answerss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "020ea1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the progress of your tax return\n"
     ]
    }
   ],
   "source": [
    "#This is to play the final thanking audio, and print out the intent that was identified.\n",
    "\n",
    "if answerss['is_affirmative'] == True:\n",
    "    playaudio('audio/thanks.wav')\n",
    "    print(answers['intent'])\n",
    "else:\n",
    "    print('confused')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
